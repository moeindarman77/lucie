# LUCIE - Learning with Unified Climate Intelligence Engine

A PyTorch-based research project for climate data super-resolution using diffusion models and Fourier Neural Operators (FNOs). LUCIE implements stable diffusion models for climate data downscaling and super-resolution, working with ERA5 climate datasets.

## Overview

LUCIE combines two powerful approaches for climate modeling:
- **Fourier Neural Operators (FNO)**: For initial super-resolution of climate variables
- **Latent Diffusion Models (DDPM)**: For refinement and uncertainty quantification

The project focuses on downscaling low-resolution climate data to high-resolution predictions for multiple atmospheric variables including temperature, precipitation, and wind components.

## Features

- ğŸŒ¡ï¸ Multi-variable climate modeling (temperature, precipitation, u-wind, v-wind)
- ğŸ”¬ Two-stage pipeline: FNO + Diffusion models
- ğŸš€ Distributed training on HPC systems with SLURM
- ğŸ“Š Comprehensive diagnostic and visualization tools
- âš™ï¸ YAML-based configuration system
- ğŸ”„ Support for model retraining and ensemble generation

## Repository Structure

```
lucie/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/          # Model architectures (FNO, U-Net, VAE, etc.)
â”‚   â”œâ”€â”€ dataset/         # Dataset loaders for ERA5 and LUCIE data
â”‚   â”œâ”€â”€ tools/           # Training and sampling scripts
â”‚   â”œâ”€â”€ config/          # YAML configuration files
â”‚   â”œâ”€â”€ utils/           # Utility functions and helpers
â”‚   â”œâ”€â”€ scheduler/       # Learning rate schedulers
â”‚   â”œâ”€â”€ data_processing/ # Data concatenation and preprocessing
â”‚   â”œâ”€â”€ diagnostics/     # Diagnostic and verification scripts
â”‚   â”œâ”€â”€ computation/     # Statistics and climatology computation
â”‚   â”œâ”€â”€ visualization/   # Visualization and comparison tools
â”‚   â””â”€â”€ tests/           # Test scripts
â”œâ”€â”€ jobs/               # SLURM job scripts
â”‚   â”œâ”€â”€ training/       # Training job scripts
â”‚   â”œâ”€â”€ testing/        # Testing and sampling jobs
â”‚   â”œâ”€â”€ concat/         # Data concatenation jobs
â”‚   â”œâ”€â”€ retrain/        # Retraining jobs
â”‚   â”œâ”€â”€ climatology/    # Climatology computation jobs
â”‚   â”œâ”€â”€ diagnostics/    # Diagnostic jobs
â”‚   â””â”€â”€ fno/            # FNO-specific jobs
â”œâ”€â”€ scripts/            # Shell scripts for job submission
â”œâ”€â”€ docs/               # Documentation
â””â”€â”€ outputs/            # Job output logs
```

## Installation

### Prerequisites

- Python 3.8+
- PyTorch 1.12+
- CUDA 11.3+ (for GPU support)
- Access to NCAR's Derecho HPC system (for full workflow)

### Environment Setup

```bash
# Clone the repository
git clone https://github.com/moeindarman77/lucie.git
cd lucie

# Create conda environment
conda create -n lucie python=3.9
conda activate lucie

# Install dependencies
pip install -r src/requirements.txt

# Set Python path
export PYTHONPATH="${PYTHONPATH}:/path/to/lucie/src"
```

### On NCAR Derecho

```bash
# Load required modules
module load conda
conda activate jax

# Set Python path
export PYTHONPATH="/glade/derecho/scratch/mdarman/lucie/src"
```

## Quick Start

### 1. Training Models

#### Train Fourier Neural Operator (FNO)
```bash
cd src
python tools/train_fno_final.py --config config/ERA5_config_fno.yaml
```

#### Train Diffusion Model
```bash
python tools/train_ddpm_final_v2.py --config config/ERA5_config_final_v2.yaml
```

#### Using SLURM
```bash
# Submit training job
qsub jobs/training/job.slurm

# Submit array job for multiple experiments
qsub jobs/training/job_array.slurm
```

### 2. Sampling/Inference

```bash
# Sample from trained model
python tools/sample_ddpm_final_v2.py --config config/ERA5_config_final_v2.yaml

# Sample for 10-year LUCIE evaluation
python tools/sample_ddpm_lucie_10yr.py --config config/ERA5_config_lucie_10yr.yaml
```

### 3. Data Processing

```bash
# Concatenate output files
./scripts/submit_all_concat_jobs.sh

# Compute climatology
qsub jobs/climatology/job_compute_climatology.slurm
```

## Configuration

All experiments are configured via YAML files in `src/config/`. Key configuration files:

- `ERA5_config_final_v2.yaml` - Main diffusion model configuration
- `ERA5_config_fno.yaml` - FNO model configuration
- `ERA5_config_lucie_10yr.yaml` - 10-year sampling configuration
- `ERA5_config_normalized_fno.yaml` - Normalized FNO setup

### Key Configuration Parameters

```yaml
dataset_params:
  data_path: "/path/to/data"
  normalization_stats: "/path/to/stats.npz"

fno_params:
  modes: 12
  width: 64

train_params:
  learning_rate: 0.0001
  batch_size: 8
  epochs: 100

diffusion_params:
  timesteps: 1000
  beta_schedule: "linear"
```

## Model Pipeline

### Two-Stage Training

1. **Stage 1: FNO Training**
   - Train FNO for initial super-resolution
   - Generates coarse high-resolution predictions

2. **Stage 2: Diffusion Model Training**
   - Uses FNO outputs as conditioning
   - Refines predictions with latent diffusion

### Data Flow

```
Low-Res ERA5 â†’ FNO â†’ Coarse HR â†’ Diffusion â†’ Fine HR Predictions
     â†“                                â†“
Land-Sea Mask â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Diagnostic Tools

The project includes comprehensive diagnostic utilities:

```bash
# Verify concatenated files
python src/diagnostics/verify_concatenated_files.py

# Check FNO statistics
python src/diagnostics/verify_fno_stats.py

# Diagnose wind component issues
python src/diagnostics/diagnose_vwind.py

# Check sampling progress
python src/diagnostics/check_sampling_progress.py
```

## Visualization

```bash
# Visualize normalized FNO samples
python src/visualization/visualize_normalized_fno_samples.py

# Compare FNO vs Diffusion outputs
python src/visualization/compare_fno_vs_diffusion.py
```

## Documentation

Detailed documentation is available in the `docs/` directory:

- [Production Run Instructions](docs/PRODUCTION_RUN_INSTRUCTIONS.md)
- [Normalization Data Flow](docs/NORMALIZATION_DATA_FLOW.md)
- [10-Year Sampling README](docs/LUCIE_10YR_SAMPLING_README.md)
- [VWind Bias Root Cause Analysis](docs/VWIND_BIAS_ROOT_CAUSE.md)

## Scripts

Convenience scripts for common workflows:

```bash
# Auto-submit training jobs
./scripts/auto_submit_training.sh

# Submit all concatenation jobs
./scripts/submit_all_concat_jobs.sh

# Check climatology computation status
./scripts/check_climatology_status.sh

# Test normalized FNO stability
./scripts/test_normalized_fno_stability.sh
```

## Data Requirements

- ERA5 climate reanalysis data in HDF5 format
- Normalization statistics files (.npz)
- Land-sea mask files for conditioning
- Organized by year and temporal resolution

## Output Structure

Results are saved in `results/` directory:
```
results/
â”œâ”€â”€ checkpoints/       # Model checkpoints
â”œâ”€â”€ samples/          # Generated samples
â”œâ”€â”€ logs/             # Training logs
â””â”€â”€ config.yaml       # Copy of configuration
```

## Citation

If you use LUCIE in your research, please cite:

```bibtex
@software{lucie2025,
  title={LUCIE: Learning with Unified Climate Intelligence Engine},
  author={Darman, Moein},
  year={2025},
  url={https://github.com/moeindarman77/lucie}
}
```

## License

[Add your license here]

## Contact

For questions and support, please open an issue on GitHub or contact:
- Moein Darman - [GitHub](https://github.com/moeindarman77)

## Acknowledgments

- NCAR's Derecho HPC system
- ERA5 climate reanalysis dataset
- PyTorch and the deep learning community
