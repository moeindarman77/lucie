dataset_params:
  input_data_dir: '/glade/derecho/scratch/asheshc/ERA5_t30/train'
  output_data_dir: '/glade/derecho/scratch/asheshc/ERA5_hr'
  normalize: True
  input_normalization_dir: '/glade/derecho/scratch/mdarman/lucie/stats_lr_2000_2009.npz'
  output_normalization_dir: '/glade/derecho/scratch/mdarman/lucie/stats_hr_2000_2009.npz'
  lucie_file_path: '/glade/derecho/scratch/mdarman/lucie/LUCIE_inference_start2010.npz'
  year_range_start: 2000
  year_range_end: 2009
  num_train_data: 9131 # 9131 for 25 years 
  total_data: 10922 # 10922 for 31 years
  test_data_beg: 9131 #range(9130, 10226) is from 25 to 28 years
  test_data_end: 10226 #range(10226, 10922) is from 28 to 31 years
  lat_lon_keep: [17.1, 30.9, -98.0, -74.1]
  input_channels: 6
  land_sea_mask: 1 # 1 for True, 0 for False
  land_sea_mask_dir: '/glade/derecho/scratch/mdarman/lucie/lsm.npz'
  output_channels: 2
  im_size_x : 344 # size of padded image
  im_size_y : 600 # size of padded image
  name: 'celebhq'

diffusion_params:
  num_timesteps : 1000
  beta_start : 0.00085
  beta_end : 0.012

ldm_params:
  down_channels: [ 256, 384, 512, 768 ]
  # down_channels: [ 32, 64, 128]
  mid_channels: [ 768, 512 ]
  # mid_channels: [ 128, 64]
  down_sample: [ True, True, False]
  attn_down : [True, True, True]
  # attn_down : [True, True]
  time_emb_dim: 512
  norm_channels: 32
  num_heads: 2
  conv_out_channels : 128
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  condition_config:
    condition_types: ['image']
    image_condition_config:
      image_condition_input_channels: 6
      image_condition_output_channels: 2
      image_condition_h : 352
      image_condition_w : 608
      cond_drop_prob: 0.1

autoencoder_params:
  z_channels: 4
  codebook_size : 8192
  # down_channels : [64, 128, 256, 256]
  down_channels : [8, 16, 32, 64]
  # mid_channels : [256, 256]
  mid_channels : [64, 64]
  down_sample : [True, True, True]
  attn_down : [False, False, False]
  norm_channels: 8
  num_heads: 1
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2


train_params:
  # General training settings
  seed: 1111  # Random seed for reproducibility
  task_name: 'ae_regional_us_v1'  # Name of the current training task
  description : 'LSM On, AE trained on US instead of globe, kl loss low, only mse'  # Description of the training task
  results_dir: '/glade/derecho/scratch/mdarman/lucie/results'  # Directory to save results: task_dir = os.path.join(results_dir, train_config['task_name'])
  load_dir: '/glade/derecho/scratch/mdarman/lucie/results'  # Directory to load results from
  load_from_checkpoint: False  # Whether to load the model from a previous checkpoint
  vae_autoencoder_resume_ckpt_path: '/glade/derecho/scratch/mdarman/lucie/results/vae_concat_v4/checkpoints/latest_autoencoder_epoch25.pth'  # Path to the model checkpoint
  vae_discriminator_resume_ckpt_path: '/glade/derecho/scratch/mdarman/lucie/results/vae_concat_v4/checkpoints/latest_discriminator_epoch25.pth'  # Path to the model checkpoint

  # Batch sizes and memory-related configurations
  ldm_batch_size: 4  # Batch size for latent diffusion model (LDM) training (limited by GPU capacity: for Derecho 1 per GPU)
  autoencoder_batch_size: 256  # Batch size for autoencoder training (limited by GPU capacity: for Derecho 2 per GPU)
  
  # Discriminator settings
  disc_start: 10  # Epoch to start training the discriminator
  disc_weight: 0.5  # Weight for discriminator loss

  # KL divergence annealing
  kl_start: 0.0  # Starting value of the KL weight
  kl_end: 0.01  # Final value of the KL weight
  kl_anneal_epochs: 50  # Number of epochs over which to anneal the KL weight
  kl_weight: 0.5  # Weight of the KL divergence loss in the overall loss

  # Weights for other loss components
  codebook_weight: 1  # Weight for the codebook loss in VQ-VAE
  commitment_beta: 0.2  # Commitment loss weight for VQ-VAE
  perceptual_weight: 1  # Weight for perceptual loss
  lambda_fft: 0.0  # Weight for FFT loss

  # Training duration
  ldm_epochs: 100  # Number of epochs for training the latent diffusion model (LDM)
  autoencoder_epochs: 100  # Number of epochs for training the autoencoder

  # Sampling settings
  num_samples: 100  # Number of samples to generate during evaluation
  num_grid_rows: 1  # Number of grid rows for sample generation visualization

  # Learning rates for different models
  ldm_lr: 0.000005  # Learning rate for the latent diffusion model (LDM)
  autoencoder_lr: 0.0001  # Learning rate for the autoencoder

  # Scheduler settings for learning rate decay
  scheduler_step_size_g: 10  # Step size for learning rate scheduler (generator)
  scheduler_gamma_g: 0.90  # Gamma for learning rate decay (generator)
  scheduler_step_size_d: 10  # Step size for learning rate scheduler (discriminator)
  scheduler_gamma_d: 0.90  # Gamma for learning rate decay (discriminator)

  # Gradient accumulation settings
  autoencoder_accumulation_steps: 8  # Number of steps to accumulate gradients for autoencoder
  autoencoder_img_save_steps: 64  # Steps interval for saving images during autoencoder training

  # Checkpoint and saving settings
  ldm_save_interval: 10  # Interval (in epochs) to save LDM checkpoints
  checkpoint_interval: 5  # Interval (in epochs) to save model checkpoints
  save_latents: False  # Whether to save latent representations during training
  load_latents: False  # Whether to loasd latent representations during training

  # Classifier-free guidance settings
  cf_guidance_scale: 1.0  # Scaling factor for classifier-free guidance during inference

  # Directories for saving latent representations
  vae_latent_dir_name: 'vae_latents'  # Directory name for VAE latents
  vqvae_latent_dir_name: 'vqvae_latents'  # Directory name for VQ-VAE latents

  # Checkpoint file names
  ldm_ckpt_name: 'ddpm_ckpt.pth'  # Checkpoint file name for LDM
  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'  # Checkpoint file name for VQ-VAE autoencoder
  vae_autoencoder_ckpt_name: 'vae_autoencoder_ckpt.pth'  # Checkpoint file name for VAE autoencoder
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'  # Checkpoint file name for VQ-VAE discriminator
  vae_discriminator_ckpt_name: 'vae_discriminator_ckpt.pth'  # Checkpoint file name for VAE discriminator